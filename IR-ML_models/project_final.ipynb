{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e6bc42-8bae-4350-bcd8-328002552a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('C:/Users/gauth/Desktop/courses/CS5604/project/dataset1/combined_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c451a82-f4d2-47a4-8898-e49af14bd739",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'Center': 0, 'Lean Left': 1, 'Lean Right': 2, 'Left': 3, 'Right': 4}\n"
     ]
    }
   ],
   "source": [
    "# Keep only the 'text' and 'bias' columns\n",
    "df = df[['text', 'bias']]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assume 'df' is your DataFrame and 'bias' is the column with categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['bias_encoded'] = label_encoder.fit_transform(df['bias'])\n",
    "\n",
    "# To see the mapping of labels to integers\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32377ec2-6202-4f92-8286-030d753066b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique bias values: [3 1 0 2 4]\n"
     ]
    }
   ],
   "source": [
    "unique_bias_values = df['bias_encoded'].unique()\n",
    "\n",
    "# To print the unique values\n",
    "print(\"Unique bias values:\", unique_bias_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2149bd-cf46-449a-9778-78125c0de25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import utils\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "def textClean(text):\n",
    "    \"\"\"\n",
    "    Get rid of the non-letter and non-number characters\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = text.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return (text)\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    text = textClean(text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return text\n",
    "\n",
    "\n",
    "def constructLabeledSentences(data):\n",
    "    sentences = []\n",
    "    for index, row in data.iteritems():\n",
    "        sentences.append(LabeledSentence(utils.to_unicode(row).split(), ['Text' + '_%s' % str(index)]))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b2e0c63-9dde-4938-8f2b-ed299f03e592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply cleanup function to your text data\n",
    "df['clean_text'] = df['text'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "537e03eb-40aa-4329-adfe-03a682135f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Extraction with TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=300)\n",
    "X_tfidf = tfidf.fit_transform(df['clean_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe403eb-9f1a-47c1-8988-41e22c2cda0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_tfidf, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxtr_tfidf.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,X_train)\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxte_tfidf.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['bias_encoded'], test_size=0.2, random_state=42)\n",
    "np.save('xtr_tfidf.npy',X_train)\n",
    "np.save('xte_tfidf.npy',X_test)\n",
    "np.save('ytr_tfidf.npy',y_train)\n",
    "np.save('yte_tfidf.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f06b4d-2c47-4d6f-a026-1687f56aa5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54     35621\n",
      "           1       0.47      0.53      0.50     35540\n",
      "           2       0.73      0.63      0.67     35497\n",
      "           3       0.47      0.48      0.47     35541\n",
      "           4       0.53      0.54      0.54     35321\n",
      "\n",
      "    accuracy                           0.54    177520\n",
      "   macro avg       0.55      0.54      0.54    177520\n",
      "weighted avg       0.55      0.54      0.54    177520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assuming you have already loaded your dataset into x_train, x_test, y_train, y_test\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe0b90ea-c791-48eb-8056-8a6b216af8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     35621\n",
      "           1       0.89      0.91      0.90     35540\n",
      "           2       0.97      0.97      0.97     35497\n",
      "           3       0.93      0.92      0.92     35541\n",
      "           4       0.93      0.90      0.91     35321\n",
      "\n",
      "    accuracy                           0.93    177520\n",
      "   macro avg       0.93      0.93      0.93    177520\n",
      "weighted avg       0.93      0.93      0.93    177520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a60dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "x_train = np.load('./xtr_tfidf.npy', allow_pickle=True)\n",
    "x_test = np.load('./xte_tfidf.npy', allow_pickle=True)\n",
    "y_train = np.load('./ytr_tfidf.npy', allow_pickle=True)\n",
    "y_test = np.load('./yte_tfidf.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the evaluation data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173a569-3e17-4b79-af22-3c9c5b0b4397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbc.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gbc.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd6b25-22db-49ba-8a26-cb37f21426c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, alpha=1e-4,\n",
    "                    solver='adam', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.01)\n",
    "\n",
    "mlp.fit(x_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f67808-6de5-4602-8212-2de96fdcbb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
